{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 1: Load timing data from .jsonl files\n",
    "# --------------------------------------------\n",
    "\n",
    "def load_jsonl_timings(label, path, file):\n",
    "    file_path = os.path.join(path, file)\n",
    "    rows = []\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"No file at: {file_path}\")\n",
    "        return rows\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                rows.append({\n",
    "                    \"type\": label,\n",
    "                    \"start_ms\": int(data[\"start_ms\"]),\n",
    "                    \"duration_ms\": int(data[\"duration_ms\"])\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to parse line: {e}\")\n",
    "    return rows\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": \"Arial\",\n",
    "    \"font.size\": 9,\n",
    "    \"axes.titlesize\": 10,\n",
    "    \"axes.labelsize\": 9,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"figure.titlesize\": 10,\n",
    "})\n",
    "\n",
    "# Color Accessibility Pallette Tool\n",
    "# https://gka.github.io/palettes/#/5|s|ffb000,fe6100,dc267f,785ef0,648fff|ffffe0,ff005e,93003a|0|1\n",
    "\n",
    "custom_colors = ['#ffb000', '#f86c36', '#dc267f', '#9d62d6', '#648fff', '#00bfc4', '#90d200']\n",
    "\n",
    "def run_analysis(label_to_path_dict, output_prefix, data_file):\n",
    "    rows = []\n",
    "    for label, path in label_to_path_dict.items():\n",
    "        rows += load_jsonl_timings(label, path, data_file)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        print(\"âš ï¸ No timing data available. Skipping analysis.\")\n",
    "        return\n",
    "\n",
    "    # Ensure experiments directory exists\n",
    "    base_dir = f\"experiments/{output_prefix}\"\n",
    "    os.makedirs(f\"{base_dir}_plots\", exist_ok=True)\n",
    "\n",
    "    # Save summary CSVs\n",
    "    df.to_csv(f\"{base_dir}_timings_summary.csv\", index=False)\n",
    "    print(f\"âœ… Saved timing summary to {base_dir}_timings_summary.csv\")\n",
    "\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"start_ms\"], unit=\"ms\")\n",
    "    summary_table = df.groupby(\"type\")[\"duration_ms\"].describe()\n",
    "    print(f\"\\nðŸ“Š Summary Table ({output_prefix}):\")\n",
    "    print(summary_table)\n",
    "    summary_table.to_csv(f\"{base_dir}_timings_stats.csv\")\n",
    "\n",
    "    n_labels = df[\"type\"].nunique()\n",
    "\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(5.5, 4.5))\n",
    "\n",
    "    # Draw the Seaborn step histogram\n",
    "    sns.histplot(\n",
    "        data=df,\n",
    "        x=\"duration_ms\",\n",
    "        hue=\"type\",\n",
    "        element=\"step\",\n",
    "        bins=30,\n",
    "        common_norm=False,\n",
    "        stat=\"count\",\n",
    "        palette=custom_colors[:df[\"type\"].nunique()],\n",
    "        legend=False  # Disable the broken default legend\n",
    "    )\n",
    "\n",
    "    # Manually build the legend\n",
    "    handles = [\n",
    "        mpatches.Patch(color=custom_colors[i], label=label)\n",
    "        for i, label in enumerate(df[\"type\"].unique())\n",
    "    ]\n",
    "\n",
    "    plt.title(r\"\\textbf{Distribution of Execution Times}\")\n",
    "    plt.xlabel(\"Duration (ms)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "\n",
    "    # Place legend at the bottom, 1 column per label\n",
    "    plt.legend(\n",
    "        handles=handles,\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.2),\n",
    "        ncol=len(handles),\n",
    "        frameon=False\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/histogram.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Boxplot\n",
    "    plt.figure(figsize=(5.5, 4))  # widened from 4.5\n",
    "    sns.boxplot(data=df, x=\"type\", y=\"duration_ms\", palette=custom_colors)\n",
    "    plt.title(r\"\\textbf{Duration Variation}\")\n",
    "    plt.ylabel(\"Duration (ms)\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/boxplot.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # Violin plot\n",
    "    plt.figure(figsize=(5.5, 3.5))  # widened from 3.5 to 5.5\n",
    "    sns.violinplot(data=df, x=\"type\", y=\"duration_ms\", inner=\"box\", palette=custom_colors)\n",
    "    plt.title(r\"\\textbf{Density and Spread}\")\n",
    "    plt.ylabel(\"Duration (ms)\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/violinplot.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # CDF\n",
    "    plt.figure(figsize=(4.5, 3))\n",
    "    for i, label in enumerate(df['type'].unique()):\n",
    "        subset = df[df['type'] == label]['duration_ms'].sort_values()\n",
    "        cum_prob = range(1, len(subset) + 1)\n",
    "        plt.plot(subset, [x / len(subset) for x in cum_prob], label=label, color=custom_colors[i % len(custom_colors)])\n",
    "    plt.title(r\"\\textbf{Cumulative Distribution}\")\n",
    "    plt.xlabel(\"Duration (ms)\")\n",
    "    plt.ylabel(\"Cumulative Probability\")\n",
    "    plt.legend(title=None, loc='upper center',  bbox_to_anchor=(0.5, -0.2), ncol=n_labels)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/cdf.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # Trend\n",
    "    # Group-wise normalization of elapsed time\n",
    "    df[\"elapsed_sec\"] = df.groupby(\"type\")[\"start_time\"].transform(lambda x: (x - x.min()).dt.total_seconds())\n",
    "\n",
    "    plt.figure(figsize=(5.5, 4))\n",
    "    for i, label in enumerate(df[\"type\"].unique()):\n",
    "        sub_df = df[df[\"type\"] == label]\n",
    "        plt.plot(\n",
    "            sub_df[\"elapsed_sec\"],\n",
    "            sub_df[\"duration_ms\"],\n",
    "            label=label,\n",
    "            linewidth=1,\n",
    "            color=custom_colors[i % len(custom_colors)]\n",
    "        )\n",
    "\n",
    "    plt.legend(title=None, loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=n_labels)\n",
    "    plt.title(r\"\\textbf{Execution Time Trends}\")\n",
    "    plt.xlabel(\"Elapsed Time (s)\")\n",
    "    plt.ylabel(\"Duration (ms)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/trend.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Order bars consistently in summary stats\n",
    "    type_order = df[\"type\"].drop_duplicates().tolist()\n",
    "    means = df.groupby(\"type\")[\"duration_ms\"].mean().reindex(type_order)\n",
    "    stds = df.groupby(\"type\")[\"duration_ms\"].std().reindex(type_order)\n",
    "\n",
    "\n",
    "    # Bar chart with error bars\n",
    "    plt.figure(figsize=(5.5, 3.5))  # widened from 3.5\n",
    "    plt.bar(type_order, means.values, yerr=stds.values, capsize=4, color=custom_colors[:len(type_order)])\n",
    "    plt.title(r\"\\textbf{Mean Duration with Std. Dev.}\")\n",
    "    plt.ylabel(\"Duration (ms)\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/means_with_error.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Outliers\n",
    "    print(f\"\\nðŸ“‰ Outliers in {output_prefix} (> 2 std dev):\")\n",
    "    for label in df['type'].unique():\n",
    "        subset = df[df['type'] == label]\n",
    "        mu = subset[\"duration_ms\"].mean()\n",
    "        sigma = subset[\"duration_ms\"].std()\n",
    "        outliers = subset[subset[\"duration_ms\"] > mu + 2 * sigma]\n",
    "        if not outliers.empty:\n",
    "            print(f\"\\nOutliers in {label}:\")\n",
    "            print(outliers[[\"start_ms\", \"duration_ms\"]])\n",
    "\n",
    "\n",
    "# ---- Core zk-timing results ----\n",
    "core_paths = {\n",
    "    \"proof_gen\": \"json_files/1\",\n",
    "    \"proof_verify\": \"json_files/2\",\n",
    "    \"latency\": \"json_files/3\"\n",
    "}\n",
    "run_analysis(core_paths, output_prefix=\"core\", data_file=\"timings.jsonl\")\n",
    "\n",
    "# ---- Feature-based results ----\n",
    "feature_paths = {\n",
    "    \"author\": \"json_files/author\",\n",
    "    \"rate_pseudo\": \"json_files/rate_pseudo\",\n",
    "    \"pseudo_msg\": \"json_files/pseudo_msg\",\n",
    "    \"pseudo_vote\": \"json_files/pseudo_vote\",\n",
    "    \"badge\": \"json_files/badge\"\n",
    "}\n",
    "run_analysis(feature_paths, output_prefix=\"features\", data_file=\"timings.jsonl\")\n",
    "\n",
    "\n",
    "latency_feature_paths = {\n",
    "    \"author\": \"json_files/author\",\n",
    "    \"rate_pseudo\": \"json_files/rate_pseudo\",\n",
    "    \"pseudo_msg\": \"json_files/pseudo_msg\",\n",
    "    \"pseudo_vote\": \"json_files/pseudo_vote\",\n",
    "    \"badge\": \"json_files/badge\",\n",
    "    \"ban\": \"json_files/ban\", \n",
    "    \"rep\": \"json_files/rep\"\n",
    "}\n",
    "run_analysis(latency_feature_paths, output_prefix=\"latency_features\", data_file=\"features_timings.jsonl\")\n",
    "\n",
    "ban_rep_paths = {\n",
    "    \"ban\": \"json_files/ban\", \n",
    "    \"rep\": \"json_files/rep\"\n",
    "}\n",
    "run_analysis(ban_rep_paths, output_prefix=\"ban_rep\", data_file=\"features_timings.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
