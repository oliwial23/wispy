{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved timing summary to experiments/core_timings_summary.csv\n",
      "\n",
      "ðŸ“Š Summary Table (core):\n",
      "              count    mean        std     min      25%     50%      75%  \\\n",
      "type                                                                       \n",
      "latency        10.0   255.4   6.686637   248.0   250.25   253.0   261.75   \n",
      "proof_gen      10.0  1618.9  28.037475  1602.0  1606.00  1608.5  1616.50   \n",
      "proof_verify   10.0   127.9   3.348300   121.0   128.00   128.5   130.00   \n",
      "\n",
      "                 max  \n",
      "type                  \n",
      "latency        265.0  \n",
      "proof_gen     1696.0  \n",
      "proof_verify   131.0  \n",
      "\n",
      "ðŸ“‰ Outliers in core (> 2 std dev):\n",
      "\n",
      "Outliers in proof_gen:\n",
      "        start_ms  duration_ms\n",
      "6  1748530705090         1696\n",
      "No file at: json_files/author/timings.jsonl\n",
      "No file at: json_files/rate_pseudo/timings.jsonl\n",
      "âœ… Saved timing summary to experiments/features_timings_summary.csv\n",
      "\n",
      "ðŸ“Š Summary Table (features):\n",
      "             count    mean        std     min      25%     50%      75%  \\\n",
      "type                                                                      \n",
      "badge         10.0  1373.1  26.349995  1339.0  1349.00  1376.0  1383.75   \n",
      "pseudo_msg    10.0  1654.6  18.916189  1630.0  1646.75  1650.0  1661.25   \n",
      "pseudo_vote   10.0  1443.0  19.194907  1417.0  1432.00  1438.0  1455.50   \n",
      "\n",
      "                max  \n",
      "type                 \n",
      "badge        1418.0  \n",
      "pseudo_msg   1695.0  \n",
      "pseudo_vote  1482.0  \n",
      "\n",
      "ðŸ“‰ Outliers in features (> 2 std dev):\n",
      "\n",
      "Outliers in pseudo_msg:\n",
      "        start_ms  duration_ms\n",
      "9  1748530652676         1695\n",
      "\n",
      "Outliers in pseudo_vote:\n",
      "         start_ms  duration_ms\n",
      "11  1748530745810         1482\n",
      "No file at: json_files/author/features_timings.jsonl\n",
      "No file at: json_files/rate_pseudo/features_timings.jsonl\n",
      "âœ… Saved timing summary to experiments/latency_features_timings_summary.csv\n",
      "\n",
      "ðŸ“Š Summary Table (latency_features):\n",
      "             count   mean        std    min     25%    50%     75%    max\n",
      "type                                                                     \n",
      "badge         10.0  196.7  17.857771  180.0  186.00  192.0  197.75  242.0\n",
      "ban           10.0  110.5  30.656701   66.0   87.25  117.0  131.50  157.0\n",
      "pseudo_msg    10.0  258.9   6.773314  248.0  256.50  258.0  263.25  270.0\n",
      "pseudo_vote   10.0  201.1   7.264067  194.0  196.25  198.0  202.50  214.0\n",
      "rep           10.0  200.7  28.130845  162.0  178.00  201.0  214.25  245.0\n",
      "\n",
      "ðŸ“‰ Outliers in latency_features (> 2 std dev):\n",
      "\n",
      "Outliers in badge:\n",
      "         start_ms  duration_ms\n",
      "27  1748530785182          242\n",
      "âœ… Saved timing summary to experiments/ban_rep_timings_summary.csv\n",
      "\n",
      "ðŸ“Š Summary Table (ban_rep):\n",
      "      count   mean        std    min     25%    50%     75%    max\n",
      "type                                                              \n",
      "ban    10.0  110.5  30.656701   66.0   87.25  117.0  131.50  157.0\n",
      "rep    10.0  200.7  28.130845  162.0  178.00  201.0  214.25  245.0\n",
      "\n",
      "ðŸ“‰ Outliers in ban_rep (> 2 std dev):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 1: Load timing data from .jsonl files\n",
    "# --------------------------------------------\n",
    "\n",
    "def load_jsonl_timings(label, path, file):\n",
    "    file_path = os.path.join(path, file)\n",
    "    rows = []\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"No file at: {file_path}\")\n",
    "        return rows\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                rows.append({\n",
    "                    \"type\": label,\n",
    "                    \"start_ms\": int(data[\"start_ms\"]),\n",
    "                    \"duration_ms\": int(data[\"duration_ms\"])\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to parse line: {e}\")\n",
    "    return rows\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": \"Arial\",\n",
    "    \"font.size\": 9,\n",
    "    \"axes.titlesize\": 10,\n",
    "    \"axes.labelsize\": 9,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"figure.titlesize\": 10,\n",
    "})\n",
    "\n",
    "# Color Accessibility Pallette Tool\n",
    "# https://gka.github.io/palettes/#/5|s|ffb000,fe6100,dc267f,785ef0,648fff|ffffe0,ff005e,93003a|0|1\n",
    "\n",
    "custom_colors = ['#ffb000', '#f86c36', '#dc267f', '#9d62d6', '#648fff', '#00bfc4', '#90d200']\n",
    "\n",
    "def run_analysis(label_to_path_dict, output_prefix, data_file):\n",
    "    rows = []\n",
    "    for label, path in label_to_path_dict.items():\n",
    "        rows += load_jsonl_timings(label, path, data_file)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        print(\"âš ï¸ No timing data available. Skipping analysis.\")\n",
    "        return\n",
    "\n",
    "    # Ensure experiments directory exists\n",
    "    base_dir = f\"experiments/{output_prefix}\"\n",
    "    os.makedirs(f\"{base_dir}_plots\", exist_ok=True)\n",
    "\n",
    "    # Save summary CSVs\n",
    "    df.to_csv(f\"{base_dir}_timings_summary.csv\", index=False)\n",
    "    print(f\"âœ… Saved timing summary to {base_dir}_timings_summary.csv\")\n",
    "\n",
    "    df[\"start_time\"] = pd.to_datetime(df[\"start_ms\"], unit=\"ms\")\n",
    "    summary_table = df.groupby(\"type\")[\"duration_ms\"].describe()\n",
    "    print(f\"\\nðŸ“Š Summary Table ({output_prefix}):\")\n",
    "    print(summary_table)\n",
    "    summary_table.to_csv(f\"{base_dir}_timings_stats.csv\")\n",
    "\n",
    "    n_labels = df[\"type\"].nunique()\n",
    "\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(5.5, 4.5))\n",
    "\n",
    "    # Draw the Seaborn step histogram\n",
    "    sns.histplot(\n",
    "        data=df,\n",
    "        x=\"duration_ms\",\n",
    "        hue=\"type\",\n",
    "        element=\"step\",\n",
    "        bins=30,\n",
    "        common_norm=False,\n",
    "        stat=\"count\",\n",
    "        palette=custom_colors[:df[\"type\"].nunique()],\n",
    "        legend=False  # Disable the broken default legend\n",
    "    )\n",
    "\n",
    "    # Manually build the legend\n",
    "    handles = [\n",
    "        mpatches.Patch(color=custom_colors[i], label=label)\n",
    "        for i, label in enumerate(df[\"type\"].unique())\n",
    "    ]\n",
    "\n",
    "    plt.title(r\"\\textbf{Distribution of Execution Times}\")\n",
    "    plt.xlabel(\"Duration (ms)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "\n",
    "    # Place legend at the bottom, 1 column per label\n",
    "    plt.legend(\n",
    "        handles=handles,\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.2),\n",
    "        ncol=len(handles),\n",
    "        frameon=False\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/histogram.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Boxplot\n",
    "    plt.figure(figsize=(5.5, 4))  # widened from 4.5\n",
    "    sns.boxplot(data=df, x=\"type\", y=\"duration_ms\", palette=custom_colors)\n",
    "    plt.title(r\"\\textbf{Duration Variation}\")\n",
    "    plt.ylabel(\"Duration (ms)\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/boxplot.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # Violin plot\n",
    "    plt.figure(figsize=(5.5, 3.5))  # widened from 3.5 to 5.5\n",
    "    sns.violinplot(data=df, x=\"type\", y=\"duration_ms\", inner=\"box\", palette=custom_colors)\n",
    "    plt.title(r\"\\textbf{Density and Spread}\")\n",
    "    plt.ylabel(\"Duration (ms)\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/violinplot.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # CDF\n",
    "    plt.figure(figsize=(4.5, 3))\n",
    "    for i, label in enumerate(df['type'].unique()):\n",
    "        subset = df[df['type'] == label]['duration_ms'].sort_values()\n",
    "        cum_prob = range(1, len(subset) + 1)\n",
    "        plt.plot(subset, [x / len(subset) for x in cum_prob], label=label, color=custom_colors[i % len(custom_colors)])\n",
    "    plt.title(r\"\\textbf{Cumulative Distribution}\")\n",
    "    plt.xlabel(\"Duration (ms)\")\n",
    "    plt.ylabel(\"Cumulative Probability\")\n",
    "    plt.legend(title=None, loc='upper center',  bbox_to_anchor=(0.5, -0.2), ncol=n_labels)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/cdf.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # Trend\n",
    "    # Group-wise normalization of elapsed time\n",
    "    df[\"elapsed_sec\"] = df.groupby(\"type\")[\"start_time\"].transform(lambda x: (x - x.min()).dt.total_seconds())\n",
    "    #df[\"elapsed_sec\"] = (df[\"start_time\"] - df[\"start_time\"].min()).dt.total_seconds()\n",
    "    #global_min = df[\"start_time\"].min()\n",
    "    #df[\"elapsed_sec\"] = (df[\"start_time\"] - global_min).dt.total_seconds()\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(5.5, 4))\n",
    "    for i, label in enumerate(df[\"type\"].unique()):\n",
    "        sub_df = df[df[\"type\"] == label]\n",
    "        plt.plot(\n",
    "            sub_df[\"elapsed_sec\"],\n",
    "            sub_df[\"duration_ms\"],\n",
    "            label=label,\n",
    "            linewidth=1,\n",
    "            color=custom_colors[i % len(custom_colors)]\n",
    "        )\n",
    "\n",
    "    plt.legend(title=None, loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=n_labels)\n",
    "    plt.title(r\"\\textbf{Execution Time Trends}\")\n",
    "    #plt.xlim(0, df[\"elapsed_sec\"].max())\n",
    "    plt.xlabel(\"Elapsed Time (s)\")\n",
    "    plt.ylabel(\"Duration (ms)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/trend.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Order bars consistently in summary stats\n",
    "    type_order = df[\"type\"].drop_duplicates().tolist()\n",
    "    means = df.groupby(\"type\")[\"duration_ms\"].mean().reindex(type_order)\n",
    "    stds = df.groupby(\"type\")[\"duration_ms\"].std().reindex(type_order)\n",
    "\n",
    "\n",
    "    # Bar chart with error bars\n",
    "    plt.figure(figsize=(5.5, 3.5))  # widened from 3.5\n",
    "    plt.bar(type_order, means.values, yerr=stds.values, capsize=4, color=custom_colors[:len(type_order)])\n",
    "    plt.title(r\"\\textbf{Mean Duration with Std. Dev.}\")\n",
    "    plt.ylabel(\"Duration (ms)\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{base_dir}_plots/means_with_error.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Outliers\n",
    "    print(f\"\\nðŸ“‰ Outliers in {output_prefix} (> 2 std dev):\")\n",
    "    for label in df['type'].unique():\n",
    "        subset = df[df['type'] == label]\n",
    "        mu = subset[\"duration_ms\"].mean()\n",
    "        sigma = subset[\"duration_ms\"].std()\n",
    "        outliers = subset[subset[\"duration_ms\"] > mu + 2 * sigma]\n",
    "        if not outliers.empty:\n",
    "            print(f\"\\nOutliers in {label}:\")\n",
    "            print(outliers[[\"start_ms\", \"duration_ms\"]])\n",
    "\n",
    "\n",
    "# ---- Core zk-timing results ----\n",
    "core_paths = {\n",
    "    \"proof_gen\": \"json_files/1\",\n",
    "    \"proof_verify\": \"json_files/2\",\n",
    "    \"latency\": \"json_files/3\"\n",
    "}\n",
    "run_analysis(core_paths, output_prefix=\"core\", data_file=\"timings.jsonl\")\n",
    "\n",
    "# ---- Feature-based results ----\n",
    "feature_paths = {\n",
    "    \"author\": \"json_files/author\",\n",
    "    \"rate_pseudo\": \"json_files/rate_pseudo\",\n",
    "    \"pseudo_msg\": \"json_files/pseudo_msg\",\n",
    "    \"pseudo_vote\": \"json_files/pseudo_vote\",\n",
    "    \"badge\": \"json_files/badge\"\n",
    "}\n",
    "run_analysis(feature_paths, output_prefix=\"features\", data_file=\"timings.jsonl\")\n",
    "\n",
    "\n",
    "latency_feature_paths = {\n",
    "    \"author\": \"json_files/author\",\n",
    "    \"rate_pseudo\": \"json_files/rate_pseudo\",\n",
    "    \"pseudo_msg\": \"json_files/pseudo_msg\",\n",
    "    \"pseudo_vote\": \"json_files/pseudo_vote\",\n",
    "    \"badge\": \"json_files/badge\",\n",
    "    \"ban\": \"json_files/ban\", \n",
    "    \"rep\": \"json_files/rep\"\n",
    "}\n",
    "run_analysis(latency_feature_paths, output_prefix=\"latency_features\", data_file=\"features_timings.jsonl\")\n",
    "\n",
    "ban_rep_paths = {\n",
    "    \"ban\": \"json_files/ban\", \n",
    "    \"rep\": \"json_files/rep\"\n",
    "}\n",
    "run_analysis(ban_rep_paths, output_prefix=\"ban_rep\", data_file=\"features_timings.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
